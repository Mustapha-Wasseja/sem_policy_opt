{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "Supervised ML focuses on prediction, but it is actions that influence the world. Predictions can be useful inputs into decision-making, but decision-making involves a subsequent optimization step which we currently devote less energy to.\n",
    "\n",
    "Reinforcement learning (RL) directly optimizes actions. But RL research is focused on very different problems than those where supervised ML is providing value today. This notebook shows a decision optimization workflow designed for mainstream business applications. \n",
    "\n",
    "My interactions with data scientists outside the tech giants convince me that this approach will add at least as much value as businesses have received from adopting supervised ML so far.\n",
    "\n",
    "The workflow is:\n",
    "1. Encode a practitioners domain knowledge into a model. This model can be a system of multiple equations, depicting different moving parts of the business environment.\n",
    "2. Use existing data to estimate parameters of the relationships described in the model. More detail on this below.\n",
    "3. Treat the estimated model as a simulation environment. Optimize the decision policy in this simulation environment.\n",
    "4. Apply that decision policy in the real business environment\n",
    "\n",
    "### Differences from Conventional RL\n",
    "\n",
    "This approach differs from mainstream RL in 3 ways:\n",
    "\n",
    "1. The RL community generally eschews human engineered models. I go the opposite direction, relying on human knowledge to structure the model.\n",
    "\n",
    "2. RL research is computationally difficult because it is applied to problems with high dimensional state spaces (e.g. robotics and video games). I focus on problems where state spaces are several orders of magnitude smaller. Optimization is much easier in such low dimensional spaces.\n",
    "\n",
    "3. Conventional RL agents learn by interacting directly with the environment. But no business would deploy an untrained agent to experiment with important business decisions. Instead, I do optimization offline (in the simulator). Only the optimized policy would be deployed to a real environment.\n",
    "\n",
    "> Though I use a model, this workflow is not conventional model-based reinforcement learning. Specifically, the model of the environment isn't updated during policy optimization. This difference flows from the goal of doing policy optimization outside the real environment.\n",
    "This approach is closer to [World Models](https://arxiv.org/abs/1803.10122). But World Models avoids human knowledge when building the simulator, relying instead on standard deep learning models. My approach would fail in the World Models testbed (a video game) because humans have little intuition in the pixel space. But humans have good intuitions about the problems I aim to solve, and that knowledge is a beneficial regularizer in my proposed workflow.\n",
    "\n",
    "# Example: Airline Pricing\n",
    "Airlines already use machine learning models to help set ticket prices. The ML model predicts how many tickets the airline can sell each day for each upcoming flight for each candidate price. The models consider price, seasonablity, competitor prices, macroeconomic variables, etc. But even a perfect predictive model doesn't guarantee efficient price setting.\n",
    "\n",
    "For example, consider a flight happening in 100 days with 150 unsold seats. A predictive model says you can sell 1 ticket today for \\\\$300 or you could sell 2 tickets if you set the price at $250. Which price should you choose? \n",
    "\n",
    "Airlines currently convert predictive models into pricing decisions with shockingly simple heuristics (e.g. a table of how many tickets to sell at pre-specified periods before the flight)\n",
    "\n",
    "This notebook trains an agent to set prices through a more formal and flexible optimization process. \n",
    "\n",
    "To illustrate the how resulting pricing policies perform in the original data generating environment, I use a simulation for the data generating process rather than using real data. Though I take a fixed dataset for trainng the predictive model in the conventional way. \n",
    "\n",
    "For illustrative simplicity, this example considers a market with only two airlines. I train an agent to set prices for Jetblue, facing a competitor called Delta.\n",
    "\n",
    "### The Two Models\n",
    "\n",
    "I use two models:\n",
    "The **structural model** defines the parts of the market that a domain expert can specify. The structural model used in this example is straightforward.  It is implemented in this code [This code](https://github.com/dansbecker/sem_policy_opt/blob/master/sem_policy_opt/market.py#L45).\n",
    "\n",
    "The key facts encoded in the model are:\n",
    "\n",
    "Each flight starts with a fixed number of available seats and a fixed number of days to departure. \n",
    "\n",
    "Each day until the flight happens\n",
    "- airlines can update the ticket price daily\n",
    "- the number of seats available decreases by the number of seats that airline sells\n",
    "- the number of days until the flight decreases by 1\n",
    "- accumulated revenue for the flight increases by `ticket_price * seats_sold`\n",
    "- airlines cannot sell more seats than the plane has, and sales stop when the plane takes off (this model ignores overbooking, though someone more knowledgeable might add it to the model)\n",
    "\n",
    "\n",
    "The second model is the **predictive model**, which captures things the airline is uncertain about:\n",
    "- How their competitor sets prices\n",
    "- How many seats each airline will sell on each day (as a function of daily demand shocks and each airline's price)\n",
    "\n",
    "I start by conventional [deep learning model](https://github.com/dansbecker/sem_policy_opt/blob/master/sem_policy_opt/keras_models.py#L22) for the predictive model. Towards the end of the notebook I use a Bayesian neural network for the predictive model and discuss the resulting benefits.\n",
    "\n",
    "The structural model is completely deterministic once it receives the predictions from the predictive model.\n",
    "\n",
    "> Aside: The field of structural econometrics has historically incorporated all uncertainty into the structural model, and not used a separate predictive model. This requires specifying functional forms in the structural model and estimating those parameters directly (e.g. with maximum likelihood estimation). That workflow has the standard shorcomings of GLM style modeling (e.g. underfitting). Abstracting uncertainty into a predictive model provides the flexibility to use modern ML.\n",
    "\n",
    "### Implementation Details\n",
    "The code captures the two models in two objects:\n",
    "- A `CompetitiveConditions` object contains the predictive model. It captures pricing strategies and the process for determining how many tickets are sold. When generating training data, the `CompetitiveConditions` object holds the true data generating process for pricing and quantity determination (rather than a predictive model). The data generating is unlike the predictive models that approximate it. Details of the data generating process for price and quantity determination aren't central to my workflow, so their description is saved for the end of this notebook.\n",
    "\n",
    "- A `Market` object contains the logic for the structural model. The `market` object takes `CompetitiveConditions` as an argument, so predictions about market dynamics can be plugged into the structural model.\n",
    "\n",
    "`Market` follows the OpenAI Gym API, allowing standard RL libraries to be used for pricing policy optimization in our model based environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Collect Data From Real Market\n",
    "\n",
    "I define parameters and import a pricing function for use in the true data generating process. The exact market mechanisms (which the constants below affect) aren't central to explaining my modeling and optimization approach. So the description of market mechanics is postponed to the bottom of this notebook.\n",
    "\n",
    "For now, you can treat the quantity-determining mechanism and it's parameters as a black box, much as the airlines do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "from sem_policy_opt.true_dgp import get_true_qty_demanded_fn\n",
    "\n",
    "# Constants hidden from airlines\n",
    "CUSTOMER_LEVEL_RANDOMNESS = 20 # Std. Dev of idiosyncratic custom preference between airlines\n",
    "DEMAND_SIGNAL_NOISINESS = 20  # Std. Dev of noise in how airlines' obversve daily traffic shocks\n",
    "MAX_DEMAND_LEVEL = 400 # The most any customer will ever pay\n",
    "POTENTIAL_CUSTOMERS_PER_DAY = 20 # Number of unique agents on consumer side of data generating process\n",
    "FLIGHTS_IN_TRAINING_DATA = 250\n",
    "FLIGHTS_IN_VAL_DATA = 25\n",
    "\n",
    "# Constants known to airlines\n",
    "SEATS_PER_FLIGHT = 250 \n",
    "SALES_WINDOW_LENGTH = 120 # Length of time airline has to sell tickets before flight takes off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used trial and error to find a reasonable pricing function. I use the following function for both airlines when creating \"real\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_price_fn(my_demand_signal, days_before_flight, my_seats_avail, competitor_full): \n",
    "    # Charge more if you have a lot of time to sell seats, if few seats are available, or if you have little competition\n",
    "    # On net, prices may increase over time because low seat inventory overwhelms remaining time effect.\n",
    "    formula_price = 50 + my_demand_signal + 0.6 * days_before_flight - my_seats_avail + 40 * int(competitor_full)\n",
    "    # demand_signal is noisy and can thus be negative. Never price tickets below some price_floor\n",
    "    price_floor = 10\n",
    "    actual_price = max(formula_price, price_floor)\n",
    "    return actual_price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Collect Training Data from Real Market\n",
    "\n",
    "Airlines have historical data they can use to build a model. Here, I run the \"real\" environment to create training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sem_policy_opt.market import Market\n",
    "from sem_policy_opt.market_conditions import CompetitiveConditions\n",
    "from sem_policy_opt.diagnostics import run_env\n",
    "\n",
    "real_market_conditions = CompetitiveConditions(delta_price_fn = simple_price_fn, \n",
    "                                               qty_fn=get_true_qty_demanded_fn(POTENTIAL_CUSTOMERS_PER_DAY, CUSTOMER_LEVEL_RANDOMNESS))\n",
    "\n",
    "real_market = Market(real_market_conditions, MAX_DEMAND_LEVEL, DEMAND_SIGNAL_NOISINESS, SEATS_PER_FLIGHT, SALES_WINDOW_LENGTH) \n",
    "\n",
    "train_profits, train_data = run_env(real_market, simple_price_fn, n_times=FLIGHTS_IN_TRAINING_DATA)\n",
    "val_profits, val_data = run_env(real_market, simple_price_fn, n_times=FLIGHTS_IN_VAL_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Fit Predictive Model on Real Data\n",
    "\n",
    "We use the training data to fit a model that predicts Delta's price and both airlines' quantity sold as a function of\n",
    "- Days remaining\n",
    "- Jetblue's demand signal\n",
    "- Jetblue's remaining number of seats available\n",
    "- Whether Delta's flight is fully booked (i.e. whether Delta is still selling tickets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "r-squared values for predictive model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'delta_price': 0.83, 'jb_qty_sold': 0.53, 'delta_qty_sold': 0.5}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pymc3 as pm\n",
    "from sem_policy_opt.pymc_models import WrappedPymcModel\n",
    "from sem_policy_opt.keras_models import WrappedKerasModel\n",
    "from sem_policy_opt.diagnostics import r_squared\n",
    "import theano\n",
    "from theano import tensor as tt\n",
    "\n",
    "predictive_model = WrappedKerasModel(train_data)\n",
    "\n",
    "print('r-squared values for predictive model:')\n",
    "r_squared(predictive_model, val_data.iloc[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Set Up Model-Based Market Simulator\n",
    "\n",
    "I create a market based not on the true data generating processes (which the Jetblue doesn't know), but instead based on the predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_market_conditions = CompetitiveConditions(predictive_model=predictive_model)\n",
    "sim_market = Market(sim_market_conditions, MAX_DEMAND_LEVEL, DEMAND_SIGNAL_NOISINESS, SEATS_PER_FLIGHT, SALES_WINDOW_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As a diagnostic, I compare predicted profits from using Jetblue's current pricing function in the training, validation and simulator data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean profits in training data: $42,093 \n",
      "Mean profits in val data: $41,815 \n",
      "Mean profits in sim data: $46,501 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "simple_price_sim_profits, simple_price_sim_data = run_env(sim_market, simple_price_fn, n_times=20)\n",
    "\n",
    "print(\"Mean profits in training data: ${:,.0f} \\n\"\n",
    "      \"Mean profits in val data: ${:,.0f} \\n\"\n",
    "      \"Mean profits in sim data: ${:,.0f} \\n\".format(train_profits.mean(), val_profits.mean(), simple_price_sim_profits.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1 Model Diagnostics\n",
    "This modeling set-up facilitates the types of diagnostics common in classical econometrics or Bayesian modeling. Beyond one example, I omit those in this notebook to move on to optimization. \n",
    "\n",
    "As an example, we can plot a demand curve and cross-price demand curve. These show how predicted ticket sales vary with respect to Jetblue's prices (holding other factors constant.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c5428dba8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "demand_curves = pd.DataFrame()\n",
    "for jb_price in np.linspace(0, MAX_DEMAND_LEVEL, 6):\n",
    "    prediction_data = pd.DataFrame(dict(days_before_flight=[150], \n",
    "                                        jb_demand_signal=[150], \n",
    "                                        delta_price=[150],\n",
    "                                        jb_price=[jb_price]))\n",
    "    prediction = predictive_model.predict(prediction_data)\n",
    "    prediction['jb_price'] = [jb_price]\n",
    "    demand_curves = pd.concat([demand_curves, pd.DataFrame(prediction)])\n",
    "demand_curves.plot(x='jb_price', y=['jb_qty_sold', 'delta_qty_sold'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-monotonicities show shortcomings of the predictive model. We would interate on the model in practical applications, but pricing policy optimization works well even with this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Optimize Policy Function\n",
    "We could use an arbitrary optimization procedure to optimize our policy. The appendix contains a Soft Actor Critic optimizer, and I may experiment with other optimizers in the future. For now, I use a simple grid search. Pricing policies are created as linear functions of the state variables\n",
    "- Daily demand signal\n",
    "- Days remaining before flight\n",
    "- Seats available\n",
    "- Whether the competitor's flight is full\n",
    "\n",
    "I try various multipliers of these state variables. The pricing equation is specified more precisely [here](https://github.com/dansbecker/sem_policy_opt/blob/master/sem_policy_opt/diagnostics.py#L9).\n",
    "\n",
    "The optimization code is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from itertools import product\n",
    "from time import time\n",
    "from sem_policy_opt.diagnostics import pricing_fn_creator, get_real_and_sim_rewards\n",
    "\n",
    "optim_start_time = time()\n",
    "\n",
    "# Create points in grid of pricing policies to be considered during optimization\n",
    "intercepts = np.linspace(0, 200, 4)\n",
    "demand_signal_mults = np.linspace(0, 1, 4)\n",
    "days_before_flight_mults = np.linspace(0, 1, 3)\n",
    "seats_avail_mults = np.linspace(-1, 0, 3)\n",
    "competitor_full_mults = np.linspace(0, 100, 3)\n",
    "price_floors = np.linspace(10, 50, 2)\n",
    "\n",
    "pricing_combinations = product(intercepts, demand_signal_mults, days_before_flight_mults, \n",
    "                               seats_avail_mults, competitor_full_mults, price_floors)\n",
    "\n",
    "pricing_fns = [pricing_fn_creator(*params) for params in pricing_combinations]\n",
    "real_and_sim_rewards = get_real_and_sim_rewards(real_market, sim_market, pricing_fns)\n",
    "\n",
    "print(\"Optimation time: {}\".format(int(time()-optim_start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A firm would select the policy that returns the highest predicted profit in simulation (since simulation is all they can see before implementing a new policy). This process is effective to the extent the policy generates higher profits in the true market environment. Predicted and real profits from various policies are shown in the following graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sem_policy_opt.diagnostics import plot_optim_results\n",
    "\n",
    "plot_optim_results(real_and_sim_rewards,\n",
    "                   baseline_real_profits=val_profits.mean(), \n",
    "                   baseline_sim_profits=simple_price_sim_profits.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis\n",
    "\n",
    "The optimization process appears effective. Did this hinge critically on the quality of the predictive model?\n",
    "\n",
    "The firm predicts demand each day from a \"demand signal\", and we have a variable that specifies how noisy these signals are.\n",
    "\n",
    "The following test varies the amount of noise in the demand signal. This in turn varies the quality of the predictive model (i.e. as measured with r-squared). The result shows the relationship between quality of the predictive model and effectiveness of policy optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sem_policy_opt.diagnostics import sensitivity_analysis\n",
    "\n",
    "noisy_real_market_maker = lambda demand_noisiness: Market(real_market_conditions, MAX_DEMAND_LEVEL, demand_noisiness, SEATS_PER_FLIGHT, SALES_WINDOW_LENGTH)\n",
    "noisy_sim_market_maker = lambda demand_noisiness, sim_conditions: Market(sim_conditions, MAX_DEMAND_LEVEL, demand_noisiness, SEATS_PER_FLIGHT, SALES_WINDOW_LENGTH)\n",
    "\n",
    "sensitivity_results = sensitivity_analysis(noisy_real_market_maker, \n",
    "                                           noisy_sim_market_maker, \n",
    "                                           noise_levels = [20, 50, 100],\n",
    "                                           pricing_fns=pricing_fns,\n",
    "                                           model_class=WrappedPymcModel,\n",
    "                                           flights_in_training_data = FLIGHTS_IN_TRAINING_DATA,\n",
    "                                           baseline_price_fn=simple_price_fn)\n",
    "sensitivity_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real profits from policy optimization decrease as the environment gets noisier (and the model gets worse). This is due to worsening optimization (and not a change in the best possible policy), as the real profits from a perfectly chosen policy remain high.\n",
    "\n",
    "Optimization beats the baseline in all circumstances, though this may be an unfair comparison as the baseline policy was chosen from ad-hoc experimentation when the baseline noise level was 20.\n",
    "\n",
    "Fortunately, simulated profits are close to real profits in all cases. So a firm would have a reasonable estimate of real profits before deploying any policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Deep Learning: Uniquely Well Suited for Decision Optimization\n",
    "\n",
    "**TODO: ADD LINK TO GITHUB WHERE MODEL IS DEFINED**\n",
    "Here I use Bayesian deep learning for the predictive model. The model architecture [defined here]() is simpler than the conventional model used thus far, and it is resultingly less accurate.\n",
    "\n",
    "However, using a Bayesian model allows me to create multiple simulators based on different parts of the model posterior (i.e. the posterior over weights in the deep learning model). Using logic akin to Jensen's inequality, we get higher expected reward by optimizing a policy while sampling from the distribution of environments, rather than optimizing given the single model environment created by a deep learning model.\n",
    "\n",
    "Results below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 4.6556e+05: 100%|██████████| 500/500 [00:04<00:00, 122.34it/s]\n",
      "Finished [100%]: Average Loss = 4.6572e+05\n"
     ]
    }
   ],
   "source": [
    "bayesian_predictive_model = WrappedPymcModel(train_data)\n",
    "\n",
    "bayesian_sim_market_conditions = CompetitiveConditions(predictive_model=bayesian_predictive_model)\n",
    "bayesian_sim_market = Market(bayesian_sim_market_conditions, \n",
    "                             MAX_DEMAND_LEVEL, \n",
    "                             DEMAND_SIGNAL_NOISINESS, \n",
    "                             SEATS_PER_FLIGHT, \n",
    "                             SALES_WINDOW_LENGTH)\n",
    "\n",
    "bayesian_simulator_results = get_real_and_sim_rewards(real_market,\n",
    "                                                      bayesian_sim_market,\n",
    "                                                      pricing_fns)\n",
    "\n",
    "print(\"Optimation time: {}\".format(int(time()-optim_start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concerns\n",
    "Price optimization nearly doubled real profits in the main example, and it consistently improved them. But I see three primary objections to this example:\n",
    "\n",
    "1) This improvement is over a baseline I created through trial and error, not a policy used in the real world (I certainly don't mean to suggest that a Fortune 500 company could double revenue this easily).\n",
    "\n",
    "2) This example is a somewhat simple problem: there are only two airlines and we didn't account for factors like seasonality. It would be straightforward to include these factors in the model, though I've yet to show how well the process works in a more complex environment.\n",
    "\n",
    "3) Most concerning, it's unclear how to show that a policy created through optimization will work well without applying it (there's nothing like a test set from supervised ML).\n",
    "\n",
    "Nevertheless, I believe this approach optimizing decision logic has amazing potential, possibly of the same order of magnitude as what we are seeing from supervised ML.\n",
    "\n",
    "I appreciate any suggestions and criticisms so I can improve the argument I've started in this notebook.\n",
    "\n",
    "# Next Steps\n",
    "\n",
    "My planned next steps are\n",
    "\n",
    "1. Abstract out the logic that's universal vs use-case specific\n",
    "2. Run on real (static) dataset rather than synthetic dataset to illustrate this workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "### How The Market In This Example Works\n",
    "Some number of customers (`POTENTIAL_CUSTOMERS_PER_DAY`) come to a website each day.  The customers' average willingness to pay for a flight on that day `demand_level`. The `demand level` on any given day is chosen from a distribution `uniform(0, MAX_DEMAND_LEVEL)`.  Each airline receives a signal about `demand_level` on that day, and the signal is the `demand_level` plus some noise that is distributed `N(0, DEMAND_SIGNAL_NOISINESS)`. This demand signal might represent a prediction of demand from a model considering seasonality, macroeconomics, etc. Additionally, each customer has idiosyncratic preferences, so their willingness to pay for a ticket on any given airline is `demand_level + customer_preference` where `customer_preference` is distributed `N(0, CUSTOMER_LEVEL_RANDOMNESS)`.  The customer considers the price for each of the two airlines and purchases a ticket from the airline that gives them the highest consumer surplus (their personal willingness to pay minus for a ticket on that airline minus the cost of a ticket on that airline).  If the customer's consumer surplus for both airlines is negative, they do not buy a ticket.\n",
    "\n",
    "### Optimization Through Modern Reinforcement Learning\n",
    "\n",
    "The cell below optimizes the pricing policy with Soft Actor Critic (SAC), an RL algorithm that is sample efficient and which is reported to require little hyperparameter tuning.\n",
    "\n",
    "NOTE: I am sharing this notebook output in Kaggle Kernels. I've not yet been able to install `stable_baselines` in kernels, so I've commented this part out for now. The value of my underlying approach doesn't hinge on whether I do optimization through SAC, grid search (used above) or something else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:    # disabled until I install stable_baselines in Kernels\n",
    "    from stable_baselines.common.vec_env import DummyVecEnv\n",
    "    from stable_baselines.sac.policies import MlpPolicy\n",
    "    from stable_baselines.sac import SAC\n",
    "    from time import time\n",
    "    import os\n",
    "\n",
    "    sim_market_maker = lambda: market_maker(sim_market_conditions)\n",
    "    \n",
    "    parallelism_level = 1         # use os.cpu_count() if not using SAC. SAC doesn't allow parallelism\n",
    "    env = DummyVecEnv([sim_market_maker for _ in range(parallelism_level)]) # Env is vectorized market for parallelism\n",
    "    total_learning_steps = 750000\n",
    "    steps_per_update = 10000\n",
    "    optim_results = []\n",
    "\n",
    "    model = SAC(MlpPolicy, env)\n",
    "\n",
    "    start_time = time()\n",
    "    for step in range(0, total_learning_steps+1, steps_per_update):\n",
    "        model.learn(total_timesteps=steps_per_update)\n",
    "    \n",
    "        mean_sim_reward = run_env(sim_market_maker, model, n_times=5)[0].mean()\n",
    "        mean_real_reward = run_env(real_market_maker, model, n_times=5)[0].mean()\n",
    "        optim_results.append(dict(step=step, \n",
    "                                  time=time()-start_time,\n",
    "                                  sim_profit=mean_sim_reward,\n",
    "                                  real_profit=mean_real_reward))\n",
    "    \n",
    "        print(\"\"\"{} timesteps used for learning in {:.0f} seconds. \n",
    "                 Current score in sim: {:.0f}. Current score in real market: {:.0f}.\"\"\".format(\n",
    "                                                                                step,\n",
    "                                                                                time()-start_time, \n",
    "                                                                                mean_sim_reward, \n",
    "                                                                                mean_real_reward))\n",
    "    optim_results_df = pd.DataFrame(optim_results)\n",
    "    optim_results_df.plot.line(x='step', y=['sim_profit', 'real_profit'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
