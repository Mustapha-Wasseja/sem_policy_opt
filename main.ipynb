{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "Machine learning focuses on making accurate predictions. But we influence the world through decisions, not predictions. Predictions can be useful inputs to improve decision-making, but models that directly help us achieve goals will be more valuable than those that only make predictions.\n",
    "\n",
    "Reinforcement learning aims to solve for optimal decision-making, but most mainstream business problems look little like existing RL work. Moreover, most RL research intentionally avoids reliance on humans' existing domain knowledge. I take the opposite approach, and show how human chosen structure expands the scope of tractible applications of RL.\n",
    "\n",
    "My approach combines RL with Structural Equation Modeling, a technique that encodes human domain knowledge into a model (typically using multiple equations that describe different parts of the domain.)\n",
    "\n",
    "My workflow is:\n",
    "1. Use structural equation modeling to create a model of the business environment. \n",
    "2. Use real data to estimate the structural model\n",
    "3. Treat the estimated model as a simulation environment, and apply reinforcement learning algorithms to find an optimal the decision policy in the simulator\n",
    "4. Apply that decision policy to make optimized decisions in the real business environment\n",
    "\n",
    "The transfer from a simulation model to the data generating environment is inspired by [world models](https://arxiv.org/abs/1803.10122) while the use of structural equation models is standard in structural microeconometrics (the field of my PhD research).\n",
    "\n",
    "I believe the approach suggested here can improve how we make decisions in a wide range of business applications.\n",
    "\n",
    "# Example Use Cases\n",
    "\n",
    "### Airline Pricing\n",
    "Airlines use machine learning models to help set ticket prices. A model predicts how many tickets the airline can sell each day for each upcoming flight for each candidate price. The models consider price, seasonablity, competitor prices, macroeconomic variables, etc. But even a perfect predictive model doesn't guarantee efficient price setting.\n",
    "\n",
    "For example, consider a flight happening in 100 days which currently has 150 unsold seats. A predictive model says you can sell 1 ticket today for \\\\$300 or you could sell 2 tickets if you set the price at $250. Which price should you choose? \n",
    "\n",
    "Airlines currently convert predictive models into pricing decisions with heuristics (e.g. a timetable of how many tickets to sell at pre-specified periods before the flight, or a goal of selling up to a pre-specified demand elasticity.)\n",
    "\n",
    "### Grocery Store Logistics\n",
    "A grocery chain ran a [predictive modeling competition on Kaggle](https://www.kaggle.com/c/favorita-grocery-sales-forecasting) to improve demand forecasts. They aimed to stock match their purchases from wholesales to their retail sales. However, the predicted sales is not always the optimal amount to stock.\n",
    "\n",
    "If you purchase exactly the amount you are predicted to sell, you will experience frequent stockouts (when your model underestimates demand), reducing sales volume and disappointing customers.  Similarly, some items will spoil when predicted sales exceed actual sales. Unless the model is exactly correct every time, you face a tradeoff.  The optimal decision would consider factors like\n",
    "- Markup rate on each item\n",
    "- Spoilage rate\n",
    "- Cost of storage\n",
    "- Value of ensuring customers find the items they want\n",
    "- etc.\n",
    "\n",
    "In practice, grocery store managers likely guess at how to make these tradeoffs, much as they may have guessed at how much of each food they would sell before adopting ML. But the approach in this notebook would help them make better decisions.\n",
    "\n",
    "\n",
    "# Implemention Overview\n",
    "This notebook focuses on the Airline Pricing example.\n",
    "\n",
    "To illustrate the how resulting pricing policies perform in the original data generating environment, I use a simulation for the data generating process rather than using real data. Though I take a fixed dataset for trainng the predictive model in the conventional way. For illustrative simplicity, this example considers a market with only two airlines.\n",
    "\n",
    "## Market Set-Up\n",
    "We train an agent to set prices for Jetblue; the competitor, whose prices we cannot control, is called Delta. \n",
    "\n",
    "There are two types of information:\n",
    "1. Information and processes that are known to the airline (such as the number of seats on each flight, days remaining before takeoff, etc.).\n",
    "2. Information and processes that aren't directly know to the airlines (their competitor's pricing policy, and the exact demand for tickets on each day). \n",
    "\n",
    "The airline builds a model to predict factors they don't directly observe. Processes they don't directly observe are stored in a `CompetitiveConditions` object. When simulating data the real environment, I build a `CompetitiveConditions` from the true data generating process. When optimizing pricing, the airline use a `CompetitiveConditions` object based on their predictive model.\n",
    "\n",
    "The other important class in the following code is the `Market`. A `Market` object holds some `CompetitiveConditions` as well as all information that airlines can directly observe. \n",
    "\n",
    "`Market` follows the OpenAI Gym API. So we can apply standard reinforcement learning tools to optimize the pricing policy from our model based environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Collect Data From Real Market\n",
    "\n",
    "We define some parameters and import a function that determine the true data generating process. The exact market mechanisms (which the constants below affect) aren't central to the optimization workflow. So a description of the market details is postponed to the bottom of this notebook.\n",
    "\n",
    "For now, you can safely treat the quantity-determining mechanism and it's parameters as a black box, much as the airlines do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sem_policy_opt.true_dgp import get_true_qty_demanded_fn\n",
    "\n",
    "# Constants hidden from airlines\n",
    "CUSTOMER_LEVEL_RANDOMNESS = 20\n",
    "DEMAND_SIGNAL_NOISINESS = 10\n",
    "MAX_DEMAND_LEVEL = 400\n",
    "POTENTIAL_CUSTOMERS_PER_DAY = 20\n",
    "\n",
    "# Constants known to airlines\n",
    "SEATS_PER_FLIGHT = 250\n",
    "SALES_WINDOW_LENGTH = 120\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used trial and error to find a reasonable pricing function. I use the following function for both airlines when creating \"real\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_price_fn(my_demand_signal, days_before_flight, my_seats_avail, competitor_full): \n",
    "    # Charge more if you have a lot of time to sell seats, if few seats are available, or if you have little competition\n",
    "    # On net, prices may increase over time because low seat inventory overwhelms remaining time effect.\n",
    "    formula_price = 50 + my_demand_signal + 0.6 * days_before_flight - my_seats_avail + 40 * int(competitor_full)\n",
    "    # demand_signal is noisy and can thus be negative. Never price tickets below some price_floor\n",
    "    price_floor = 10\n",
    "    actual_price = max(formula_price, price_floor)\n",
    "    return actual_price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Real Market\n",
    "\n",
    "Airlines have historical data they can use to build a model. Here, we run the \"real\" environment to create this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sem_policy_opt.market import Market\n",
    "from sem_policy_opt.market_conditions import CompetitiveConditions\n",
    "from sem_policy_opt.diagnostics import run_env\n",
    "\n",
    "real_market_conditions = CompetitiveConditions(delta_price_fn = simple_price_fn, \n",
    "                                               qty_fn=get_true_qty_demanded_fn(POTENTIAL_CUSTOMERS_PER_DAY, CUSTOMER_LEVEL_RANDOMNESS))\n",
    "\n",
    "real_market = Market(real_market_conditions, MAX_DEMAND_LEVEL, DEMAND_SIGNAL_NOISINESS, SEATS_PER_FLIGHT, SALES_WINDOW_LENGTH) \n",
    "\n",
    "train_profits, train_data = run_env(real_market, simple_price_fn, n_times=1000)\n",
    "val_profits, val_data = run_env(real_market, simple_price_fn, n_times=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Fit Machine Learning Model on Real Data\n",
    "\n",
    "We fit a model that predicts Delta's price and the quantity sold as a function of\n",
    "- Days remaining\n",
    "- Jetblue's demand signal\n",
    "- Jetblue's remaining number of seats available\n",
    "- Whether Delta's flight is fully booked (i.e. whether Delta is still selling tickets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "120000/120000 [==============================] - 2s 14us/step - loss: 10622.6742 - val_loss: 1434.9922\n",
      "Epoch 2/50\n",
      "120000/120000 [==============================] - 1s 9us/step - loss: 1415.4212 - val_loss: 1366.9678\n",
      "Epoch 3/50\n",
      "120000/120000 [==============================] - 1s 9us/step - loss: 1362.2093 - val_loss: 1316.7823\n",
      "Epoch 4/50\n",
      "120000/120000 [==============================] - 1s 9us/step - loss: 1312.7058 - val_loss: 1267.0454\n",
      "Epoch 5/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 1256.9478 - val_loss: 1207.9456\n",
      "Epoch 6/50\n",
      "120000/120000 [==============================] - 1s 9us/step - loss: 1194.8129 - val_loss: 1141.8817\n",
      "Epoch 7/50\n",
      "120000/120000 [==============================] - 1s 9us/step - loss: 1124.9423 - val_loss: 1071.3049\n",
      "Epoch 8/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 1050.7968 - val_loss: 1000.0497\n",
      "Epoch 9/50\n",
      "120000/120000 [==============================] - 1s 9us/step - loss: 977.5973 - val_loss: 928.2320\n",
      "Epoch 10/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 912.0218 - val_loss: 869.9703\n",
      "Epoch 11/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 860.9886 - val_loss: 827.1447\n",
      "Epoch 12/50\n",
      "120000/120000 [==============================] - 1s 9us/step - loss: 814.8474 - val_loss: 788.3938\n",
      "Epoch 13/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 786.7836 - val_loss: 778.4449\n",
      "Epoch 14/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 765.2146 - val_loss: 748.8047\n",
      "Epoch 15/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 748.4931 - val_loss: 734.2321\n",
      "Epoch 16/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 733.1288 - val_loss: 718.9668\n",
      "Epoch 17/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 717.7163 - val_loss: 700.7499\n",
      "Epoch 18/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 700.4780 - val_loss: 701.4773\n",
      "Epoch 19/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 687.0572 - val_loss: 675.2576\n",
      "Epoch 20/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 674.0885 - val_loss: 661.3394\n",
      "Epoch 21/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 663.3935 - val_loss: 647.4786\n",
      "Epoch 22/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 649.6065 - val_loss: 636.8189\n",
      "Epoch 23/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 637.0866 - val_loss: 633.0920\n",
      "Epoch 24/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 624.6456 - val_loss: 616.2622\n",
      "Epoch 25/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 613.6181 - val_loss: 596.9874\n",
      "Epoch 26/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 602.2792 - val_loss: 590.9826\n",
      "Epoch 27/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 591.0158 - val_loss: 580.5493\n",
      "Epoch 28/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 579.9435 - val_loss: 566.0606\n",
      "Epoch 29/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 570.4315 - val_loss: 557.7993\n",
      "Epoch 30/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 562.1677 - val_loss: 550.8152\n",
      "Epoch 31/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 551.0216 - val_loss: 553.4311\n",
      "Epoch 32/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 542.7500 - val_loss: 530.4815\n",
      "Epoch 33/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 534.7127 - val_loss: 533.3015\n",
      "Epoch 34/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 523.8985 - val_loss: 517.0906\n",
      "Epoch 35/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 515.6932 - val_loss: 501.7596\n",
      "Epoch 36/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 505.0436 - val_loss: 489.5145\n",
      "Epoch 37/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 494.6783 - val_loss: 480.3836\n",
      "Epoch 38/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 486.6110 - val_loss: 477.3500\n",
      "Epoch 39/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 476.0379 - val_loss: 464.0483\n",
      "Epoch 40/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 467.8796 - val_loss: 459.7511\n",
      "Epoch 41/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 458.6434 - val_loss: 455.2846\n",
      "Epoch 42/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 451.3419 - val_loss: 437.2753\n",
      "Epoch 43/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 442.3705 - val_loss: 441.9600\n",
      "Epoch 44/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 434.7217 - val_loss: 419.8586\n",
      "Epoch 45/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 430.2630 - val_loss: 413.9774\n",
      "Epoch 46/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 418.4120 - val_loss: 407.2562\n",
      "Epoch 47/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 411.8151 - val_loss: 404.3197\n",
      "Epoch 48/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 407.3861 - val_loss: 394.7079\n",
      "Epoch 49/50\n",
      "120000/120000 [==============================] - 1s 8us/step - loss: 400.5881 - val_loss: 385.9138\n",
      "Epoch 50/50\n",
      "120000/120000 [==============================] - 1s 7us/step - loss: 395.1171 - val_loss: 409.3964\n",
      "Train on 120000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "120000/120000 [==============================] - 4s 35us/step - loss: 8.6021 - delta_price_loss: 412.2404 - jb_qty_loss: 1.6239 - delta_qty_loss: 2.1065 - val_loss: -3.9525 - val_delta_price_loss: 409.3964 - val_jb_qty_loss: -0.7916 - val_delta_qty_loss: -0.7861\n",
      "Epoch 2/50\n",
      "120000/120000 [==============================] - 3s 23us/step - loss: -3.4903 - delta_price_loss: 412.2404 - jb_qty_loss: -0.7125 - delta_qty_loss: -0.6404 - val_loss: -4.2066 - val_delta_price_loss: 409.3964 - val_jb_qty_loss: -0.8470 - val_delta_qty_loss: -0.8185\n",
      "Epoch 3/50\n",
      "120000/120000 [==============================] - 3s 23us/step - loss: -3.9300 - delta_price_loss: 412.2404 - jb_qty_loss: -0.7971 - delta_qty_loss: -0.7415 - val_loss: -4.1848 - val_delta_price_loss: 409.3964 - val_jb_qty_loss: -0.8411 - val_delta_qty_loss: -0.8204\n",
      "Epoch 4/50\n",
      "120000/120000 [==============================] - 3s 24us/step - loss: -4.0715 - delta_price_loss: 412.2404 - jb_qty_loss: -0.8269 - delta_qty_loss: -0.7638 - val_loss: -4.1569 - val_delta_price_loss: 409.3964 - val_jb_qty_loss: -0.8411 - val_delta_qty_loss: -0.7926\n",
      "Epoch 5/50\n",
      "120000/120000 [==============================] - 3s 24us/step - loss: -4.1183 - delta_price_loss: 412.2404 - jb_qty_loss: -0.8344 - delta_qty_loss: -0.7806 - val_loss: -4.2365 - val_delta_price_loss: 409.3964 - val_jb_qty_loss: -0.8560 - val_delta_qty_loss: -0.8124\n",
      "Epoch 6/50\n",
      "120000/120000 [==============================] - 3s 24us/step - loss: -4.1558 - delta_price_loss: 412.2404 - jb_qty_loss: -0.8414 - delta_qty_loss: -0.7904 - val_loss: -4.2857 - val_delta_price_loss: 409.3964 - val_jb_qty_loss: -0.8654 - val_delta_qty_loss: -0.8240\n",
      "Epoch 7/50\n",
      "120000/120000 [==============================] - 3s 24us/step - loss: -4.1679 - delta_price_loss: 412.2404 - jb_qty_loss: -0.8435 - delta_qty_loss: -0.7938 - val_loss: -4.1794 - val_delta_price_loss: 409.3964 - val_jb_qty_loss: -0.8399 - val_delta_qty_loss: -0.8199\n",
      "Epoch 8/50\n",
      "120000/120000 [==============================] - 3s 24us/step - loss: -4.1956 - delta_price_loss: 412.2404 - jb_qty_loss: -0.8491 - delta_qty_loss: -0.7993 - val_loss: -4.2387 - val_delta_price_loss: 409.3964 - val_jb_qty_loss: -0.8541 - val_delta_qty_loss: -0.8224\n",
      "Epoch 9/50\n",
      "120000/120000 [==============================] - 3s 24us/step - loss: -4.2043 - delta_price_loss: 412.2404 - jb_qty_loss: -0.8511 - delta_qty_loss: -0.7999 - val_loss: -4.2345 - val_delta_price_loss: 409.3964 - val_jb_qty_loss: -0.8548 - val_delta_qty_loss: -0.8154\n",
      "Epoch 10/50\n",
      "120000/120000 [==============================] - 3s 24us/step - loss: -4.2221 - delta_price_loss: 412.2404 - jb_qty_loss: -0.8550 - delta_qty_loss: -0.8021 - val_loss: -4.2584 - val_delta_price_loss: 409.3964 - val_jb_qty_loss: -0.8623 - val_delta_qty_loss: -0.8093\n",
      "Epoch 11/50\n",
      "120000/120000 [==============================] - 3s 24us/step - loss: -4.2252 - delta_price_loss: 412.2404 - jb_qty_loss: -0.8547 - delta_qty_loss: -0.8062 - val_loss: -4.2719 - val_delta_price_loss: 409.3964 - val_jb_qty_loss: -0.8604 - val_delta_qty_loss: -0.8305\n",
      "{'delta_price_r2': 0.971098219340336, 'jb_qty_sold_r2': 0.6998958169507777, 'delta_qty_sold_r2': 0.6743210576470031}\n"
     ]
    }
   ],
   "source": [
    "from sem_policy_opt.keras_models import get_keras_model, prep_for_keras_model\n",
    "from sem_policy_opt.diagnostics import r_squared\n",
    "\n",
    "train_x, train_y = prep_for_keras_model(train_data)\n",
    "val_x, val_y = prep_for_keras_model(val_data)\n",
    "predictive_model = get_keras_model(train_x, train_y, val_x, val_y, verbose=1)\n",
    "\n",
    "print(r_squared(predictive_model, val_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Set Up Model-Based Market Simulator\n",
    "\n",
    "Now we create a market based not on the true data generating processes (which the firms don't know), but instead based on the predictive model.\n",
    "\n",
    "As a diagnostic, I compare predicted profits from using Jetblue's current pricing function in the training, validation and simulator data.\n",
    "\n",
    "There are important dynamics from outside the ML model used here.\n",
    "\n",
    "**TODO: DESCRIPTION OF STRUCTURAL EQUATION MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean profits in training data: 42501.5398 \n",
      "Mean profits in val data: 43340.108 \n",
      "Mean profits in sim data: 45366.084 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sim_market_conditions = CompetitiveConditions(predictive_model=predictive_model)\n",
    "# use function returning simulated market with baselines API to facilitate parallelism\n",
    "sim_market_maker = lambda: Market(sim_market_conditions, MAX_DEMAND_LEVEL, DEMAND_SIGNAL_NOISINESS, SEATS_PER_FLIGHT, SALES_WINDOW_LENGTH)\n",
    "noisy_sim_market_maker = lambda: Market(sim_market_conditions, MAX_DEMAND_LEVEL, DEMAND_SIGNAL_NOISINESS, SEATS_PER_FLIGHT, SALES_WINDOW_LENGTH, summarize_on_episode_end=True)\n",
    "sim_market = sim_market_maker()\n",
    "\n",
    "\n",
    "simple_price_sim_profits, simple_price_sim_data = run_env(sim_market, simple_price_fn, n_times=50)\n",
    "\n",
    "print(\"Mean profits in training data: {} \\n\"\n",
    "      \"Mean profits in val data: {} \\n\"\n",
    "      \"Mean profits in sim data: {} \\n\".format(train_profits.mean(), val_profits.mean(), simple_price_sim_profits.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnostics and Experiment With Different Pricing Strategies\n",
    "\n",
    "We can use the simulator to test he performance of an arbitrary pricing function.\n",
    "\n",
    "As a simple experiemnt, we first estimate revenue per flight when multiplying all prices from the existing pricing function by various constants.\n",
    "\n",
    "Results shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sem_policy_opt.diagnostics import test_pricing_multipliers\n",
    "\n",
    "price_comparison = test_pricing_multipliers(simple_price_fn, np.linspace(0.5, 1.5, 5), sim_market, real_market)\n",
    "\n",
    "print(price_comparison)\n",
    "alt.Chart(price_comparison).mark_point().encode(\n",
    "    x='mean_predicted_rev',\n",
    "    y='mean_actual_rev',\n",
    "    color='base_price_mult',\n",
    "    tooltip='base_price_mult')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at a couple more diagnostics before running a reinforcement learning algorithm to optimize our pricing function.\n",
    "\n",
    "Below, I show predicted quantities sold in a given day for various candidate jetblue prices (holding the number of days until the flight and Jetblue's demand signal constant.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_before_flight = jb_demand_signal = 150\n",
    "pred_outcomes_diff_jb_prices = []\n",
    "for jb_price in np.linspace(0, MAX_DEMAND_LEVEL, 6):\n",
    "    # Some extra munging here do to messiness associated with multi-input / multi-output model.\n",
    "    # each input fed in as separate array to facilitate hiding jetblue_price from prediction of delta_price\n",
    "    prediction_data = prep_for_keras_model([days_before_flight, jb_demand_signal, jb_price], skip_y=True)\n",
    "    prediction = predictive_model.predict(prediction_data)\n",
    "    delta_price, jb_seats_sold, delta_seats_sold = [i[0][0] for i in prediction]\n",
    "    pred_outcomes_diff_jb_prices.append({'jb_price': jb_price,\n",
    "                                         'delta_price': delta_price,\n",
    "                                         'jetblue_seats_sold': jb_seats_sold,\n",
    "                                         'delta_seats_sold': delta_seats_sold})\n",
    "pd.DataFrame(pred_outcomes_diff_jb_prices).set_index(['jb_price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's reassuring that delta price is independent of **jb_price**. Delta must choose their price without seeing Jetblue's.  However, it's a shortcoming of the model that Delta is predicted to sell fewer seats as jetblue's price increases.\n",
    "\n",
    "Even with shortcomings in the model, we can optimize a pricing policy against the model and find it improves profits in the real environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Optimize Policy Function\n",
    "Everything below is currently in-progress. Looking at RL with the `stable_baselines` library, which is a better-maintained fork of OpenAI baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.sac.policies import MlpPolicy\n",
    "from stable_baselines.sac import SAC\n",
    "from time import time\n",
    "import os\n",
    "\n",
    "parallelism_level = 1         # use os.cpu_count() if not using SAC. SAC doesn't allow parallelism\n",
    "env = DummyVecEnv([sim_market_maker for _ in range(parallelism_level)]) # Env is vectorized market for parallelism\n",
    "\n",
    "model = SAC(MlpPolicy, env)\n",
    "\n",
    "start_time = time()\n",
    "for num_updates in range(1, 10):\n",
    "    model.learn(total_timesteps=5000)\n",
    "    sim_market_rewards, _ = run_env(sim_market, model, n_times=2)\n",
    "    real_market_rewards, _ = run_env(real_market, model, n_times=2)\n",
    "    print(\"\"\"{} learn calls executed in {:.0f} seconds. \n",
    "             Current score in sim: {:.0f}. Current score in real market: {:.0f}.\"\"\".format(\n",
    "                                                                                num_updates, \n",
    "                                                                                time()-start_time, \n",
    "                                                                                sim_market_rewards.mean(), \n",
    "                                                                                real_market_rewards.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details\n",
    "\n",
    "#### How The Market Works\n",
    "Some number of customers (`POTENTIAL_CUSTOMERS_PER_DAY`) come to a website each day.  The customers' average willingness to pay for a flight on that day `demand_level`. The `demand level` on any given day is chosen from a distribution `uniform(0, MAX_DEMAND_LEVEL)`.  Each airline receives a signal about `demand_level` on that day, and the signal is the `demand_level` plus some noise that is distributed `N(0, DEMAND_SIGNAL_NOISINESS)`. This demand signal might represent a prediction of demand from a model considering seasonality, macroeconomics, etc. Additionally, each customer has idiosyncratic preferences, so their willingness to pay for a ticket on any given airline is `demand_level + customer_preference` where `customer_preference` is distributed `N(0, CUSTOMER_LEVEL_RANDOMNESS)`.  The customer considers the price for each of the two airlines and purchases a ticket from the airline that gives them the highest consumer surplus (their personal willingness to pay minus for a ticket on that airline minus the cost of a ticket on that airline).  If the customer's consumer surplus for both airlines is negative, they do not buy a ticket.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
