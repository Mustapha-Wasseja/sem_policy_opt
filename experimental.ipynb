{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "Supervised machine learning focuses on making accurate predictions. But it is our actions that influence the world, and predictions are useful only as inputs into improve decision-making. So models that effectively optimize actions will be more valuable than those that only make predictions.\n",
    "\n",
    "Reinforcement learning (RL) is the leading approach to optimizing optimizing actions. But mainstream RL faces major barriers to widespread adoption. This notebook outlines a decision optimization approach that I believe is practical in most applications where supervised ML is used today. Most of the notebook is an example going through this workflow.\n",
    "\n",
    "The workflow is:\n",
    "1. Encode a practitioners domain knowledge into a model. This model is called the **structural model** because it takes a form common in strucural econometrics and structural equation modeling. The structural model differs from common statistical and ML models by including multiple equations (which are interconnected because some variables show up in multiple equations.) \n",
    "2. Use pre-existing data to estimate the unknown parameters of the structural model. More detail on this below.\n",
    "3. Treat the estimated model as a simulation environment. Optimize the decision policy in this simulation environment.\n",
    "4. Apply that decision policy in the real business environment\n",
    "\n",
    "### Differences from Conventional RL\n",
    "\n",
    "This approach differs from mainstream RL in three important ways:\n",
    "\n",
    "1. The RL community generally prefers not to rely on human engineered models. I go the opposite direction, applying human knowledge as much as possible in the structural model.\n",
    "\n",
    "2. RL research is computationally difficult because it is applied to problems with high dimensional state spaces (e.g. robotics and video games). I focus on the types of problems where supervised ML is currently applied. These problems have orders of magnitude smaller state spaces. Optimization in these low dimensional spaces is faster and more stable than optimization in high dimensional spaces.\n",
    "\n",
    "3. RL agents learn by interacting directly with the environment. Few businesses would allow an untrained agent to experiment with their important business decisions. So the proposed workflow does optimization offline (in the simulator). Only the optimized policy is ever deployed to a real environment.\n",
    "\n",
    "\n",
    "> Though I use a model, this workflow is not conventional model-based reinforcement learning, because the model of the environment isn't updated during policy optimization. This difference flows from the goal of doing policy optimization outside of the real environment.\n",
    "This approach is closer to [World Models](https://arxiv.org/abs/1803.10122). But World Models avoids human knowledge when building the simulator, relying instead on standard deep learning models. My approach would fail in the World Models testbed (a video game) because humans have little intuition in the pixel space. But humans have good intuitions about the problems I aim to solve, and that knowledge is a beneficial regularizer in my proposed workflow.\n",
    "\n",
    "# Example Applications\n",
    "\n",
    "### Airline Pricing\n",
    "Airlines already use machine learning models to help set ticket prices. The ML model predicts how many tickets the airline can sell each day for each upcoming flight for each candidate price. The models consider price, seasonablity, competitor prices, macroeconomic variables, etc. But even a perfect predictive model doesn't guarantee efficient price setting.\n",
    "\n",
    "For example, consider a flight happening in 100 days which currently has 150 unsold seats. A predictive model says you can sell 1 ticket today for \\\\$300 or you could sell 2 tickets if you set the price at $250. Which price should you choose? \n",
    "\n",
    "Airlines currently convert predictive models into pricing decisions with heuristics (e.g. a timetable of how many tickets to sell at pre-specified periods before the flight, or a goal of selling up to a pre-specified demand elasticity.)\n",
    "\n",
    "I believe formal optimization promises a major improvement over these rule-of-thumb approaches.\n",
    "\n",
    "### Grocery Store Logistics\n",
    "A grocery chain ran a [predictive modeling competition on Kaggle](https://www.kaggle.com/c/favorita-grocery-sales-forecasting) to improve demand forecasts. They aimed to stock match their purchases from wholesales to their retail sales. However, the predicted sales is not always the optimal amount to stock.\n",
    "\n",
    "If you purchase exactly the amount you are predicted to sell, you will experience frequent stockouts (when your model underestimates demand), reducing sales volume and disappointing customers.  Similarly, some items will spoil when predicted sales exceed actual sales. Unless the model is exactly correct every time, you face a tradeoff.  The optimal decision would consider factors like\n",
    "- Markup rate on each item\n",
    "- Spoilage rate\n",
    "- Cost of storage\n",
    "- Value of ensuring customers find the items they want\n",
    "- etc.\n",
    "\n",
    "In practice, grocery store managers likely guess at how to make these tradeoffs, much as they may have guessed at how much of each food they would sell before adopting ML. But the approach in this notebook would help them make better decisions.\n",
    "\n",
    "\n",
    "# Implemented Example\n",
    "This notebook focuses on the Airline Pricing example. Specifically, I train an agent to set prices for Jetblue. The competitor, whose prices we cannot control, is called Delta. \n",
    "\n",
    "To illustrate the how resulting pricing policies perform in the original data generating environment, I use a simulation for the data generating process rather than using real data. Though I take a fixed dataset for trainng the predictive model in the conventional way. For illustrative simplicity, this example considers a market with only two airlines.\n",
    "\n",
    "### The Two Models\n",
    "\n",
    "I use two models:\n",
    "The **structural model** defines the parts of the market that a domain expert can specify. The structural model used in this example is straightforward.  It is implemented in this code [This code](https://github.com/dansbecker/sem_policy_opt/blob/master/sem_policy_opt/market.py#L45).\n",
    "\n",
    "The key facts encoded in the model are:\n",
    "\n",
    "Each flight starts with a fixed number of available seats and a fixed number of days to departure. \n",
    "\n",
    "Each day until the flight happens\n",
    "- airlines can update the ticket price daily\n",
    "- the number of seats available decreases by the number of seats that airline sells\n",
    "- the number of days until the flight decreases by 1\n",
    "- accumulated revenue for the flight increases by `ticket_price * seats_sold`\n",
    "- airlines cannot sell more seats than the plane has, and sales stop when the plane takes off (this model ignores overbooking, though someone more knowledgeable might add it to the model)\n",
    "\n",
    "\n",
    "\n",
    "The second model is the **predictive model**, which captures things the airline is uncertain about:\n",
    "- How their competitor sets prices\n",
    "- How many seats each airline will sell on each day (as a function of daily demand shocks and each airline's price)\n",
    "\n",
    "The predictive model used here is a [deep learning model](https://github.com/dansbecker/sem_policy_opt/blob/master/sem_policy_opt/keras_models.py#L22). The structural model is completely deterministic once it receives the predictions from the predictive model.\n",
    "\n",
    "> Aside: Structural econometrics has historically incorporated all uncertainty into the structural model, and not used a separate predictive model. This requires specifying all functional forms in the model and estimating those parameters directly (e.g. with maximum likelihood estimation). That workflow has the shortcomings of standard GLM style modeling ((poor predictive accuracy due to underfitting). Abstracting the sources of uncertainty into a separate predictive model allows the flexibility to use modern ML.\n",
    "\n",
    "> Second Aside: I explored representing the structural and predictive models together using PyMC3. This allow estimating full Bayesian posteriors. This has a potentially large benefit for decision optimization (related to Jensen's inequality). I found it difficult to simulate market dynamics in PyMC3. I'll revisit probabilistic programming for this purpose, likely after the release of PyMC4.\n",
    "\n",
    "### Implementation Details\n",
    "The code captures the two models in two objects:\n",
    "- A `CompetitiveConditions` object contains the predictive model. It captures pricing strategies and the process for determining how many tickets are sold. When generating training data, the `CompetitiveConditions` object holds the true data generating process for pricing and quantity determination (rather than a predictive model). The data generating is unlike the predictive models that approximate it. Details of the data generating process for price and quantity determination aren't central to my workflow, so their description is saved for the end of this notebook.\n",
    "\n",
    "- A `Market` object contains the logic for the structural model. The `market` object takes `CompetitiveConditions` as an argument, so predictions about market dynamics can be plugged into the structural model.\n",
    "\n",
    "`Market` follows the standard OpenAI Gym API, so standard RL tools can be used to optimize pricing policies in our model based environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Collect Data From Real Market\n",
    "\n",
    "I define parameters and import a pricing function for use in the true data generating process. The exact market mechanisms (which the constants below affect) aren't central to explaining my modeling and optimization approach. So the description of market mechanics is postponed to the bottom of this notebook.\n",
    "\n",
    "For now, you can treat the quantity-determining mechanism and it's parameters as a black box, much as the airlines do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sem_policy_opt.true_dgp import get_true_qty_demanded_fn\n",
    "\n",
    "# Constants hidden from airlines\n",
    "CUSTOMER_LEVEL_RANDOMNESS = 20 # Std. Dev of idiosyncratic custom preference between airlines\n",
    "DEMAND_SIGNAL_NOISINESS = 20  # Std. Dev of noise in how airlines' obversve daily traffic shocks\n",
    "MAX_DEMAND_LEVEL = 400 # The most any customer will ever pay\n",
    "POTENTIAL_CUSTOMERS_PER_DAY = 20 # Number of unique agents on consumer side of data generating process\n",
    "FLIGHTS_IN_TRAINING_DATA = 250\n",
    "FLIGHTS_IN_VAL_DATA = 25\n",
    "\n",
    "# Constants known to airlines\n",
    "SEATS_PER_FLIGHT = 250 \n",
    "SALES_WINDOW_LENGTH = 120 # Length of time airline has to sell tickets before flight takes off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used trial and error to find a reasonable pricing function. I use the following function for both airlines when creating \"real\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_price_fn(my_demand_signal, days_before_flight, my_seats_avail, competitor_full): \n",
    "    # Charge more if you have a lot of time to sell seats, if few seats are available, or if you have little competition\n",
    "    # On net, prices may increase over time because low seat inventory overwhelms remaining time effect.\n",
    "    formula_price = 50 + my_demand_signal + 0.6 * days_before_flight - my_seats_avail + 40 * int(competitor_full)\n",
    "    # demand_signal is noisy and can thus be negative. Never price tickets below some price_floor\n",
    "    price_floor = 10\n",
    "    actual_price = max(formula_price, price_floor)\n",
    "    return actual_price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Collect Training Data from Real Market\n",
    "\n",
    "Airlines have historical data they can use to build a model. Here, I run the \"real\" environment to create training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sem_policy_opt.market import Market\n",
    "from sem_policy_opt.market_conditions import CompetitiveConditions\n",
    "from sem_policy_opt.diagnostics import run_env\n",
    "\n",
    "real_market_conditions = CompetitiveConditions(delta_price_fn = simple_price_fn, \n",
    "                                               qty_fn=get_true_qty_demanded_fn(POTENTIAL_CUSTOMERS_PER_DAY, CUSTOMER_LEVEL_RANDOMNESS))\n",
    "\n",
    "real_market = Market(real_market_conditions, MAX_DEMAND_LEVEL, DEMAND_SIGNAL_NOISINESS, SEATS_PER_FLIGHT, SALES_WINDOW_LENGTH) \n",
    "\n",
    "train_profits, train_data = run_env(real_market, simple_price_fn, n_times=FLIGHTS_IN_TRAINING_DATA)\n",
    "val_profits, val_data = run_env(real_market, simple_price_fn, n_times=FLIGHTS_IN_VAL_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Fit Predictive Model on Real Data\n",
    "\n",
    "We use the training data to fit a model that predicts Delta's price and the quantity sold as a function of\n",
    "- Days remaining\n",
    "- Jetblue's demand signal\n",
    "- Jetblue's remaining number of seats available\n",
    "- Whether Delta's flight is fully booked (i.e. whether Delta is still selling tickets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[[ 1.105509   -0.00975475 -1.11823061]]\n",
      "(1, 28613)\n",
      "2.153112221717401\n",
      "Help on method sample_node in module pymc3.variational.opvi:\n",
      "\n",
      "sample_node(node, size=None, deterministic=False, more_replacements=None) method of pymc3.variational.approximations.Empirical instance\n",
      "    Samples given node or nodes over shared posterior\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    node : Theano Variables (or Theano expressions)\n",
      "    size : None or scalar\n",
      "        number of samples\n",
      "    more_replacements : `dict`\n",
      "        add custom replacements to graph, e.g. change input source\n",
      "    deterministic : bool\n",
      "        whether to use zeros as initial distribution\n",
      "        if True - zero initial point will produce constant latent variables\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    sampled node(s) with replacements\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pymc3 as pm\n",
    "from sem_policy_opt.pymc_models import WrappedPymcModel\n",
    "from sem_policy_opt.diagnostics import r_squared\n",
    "\n",
    "predictive_model = WrappedPymcModel(train_data)\n",
    "\n",
    "#trace = predictive_model.approx.sample(draws=20)\n",
    "#ppc = pm.sample_posterior_predictive(trace, samples=20, model=predictive_model.model)\n",
    "#predicted_sold=pd.DataFrame(ppc['jb_qty_sold'])\n",
    "#predicted_sold.mean().describe()\n",
    "\n",
    "pred_X = [np.array([100]), np.array([200]), np.array([100])]\n",
    "pred_X = pd.DataFrame(data=np.hstack([i[:, np.newaxis] for i in pred_X]),\n",
    "                      columns=predictive_model.predictor_names)\n",
    "transformed_data = predictive_model._prep_X(pred_X)\n",
    "print(transformed_data)\n",
    "\n",
    "\n",
    "with predictive_model.model:\n",
    "    jb_qty_preds = predictive_model.approx.sample_node(predictive_model.jb_qty_node,\n",
    "                                                       size=1,\n",
    "                                                       deterministic=False,\n",
    "                            more_replacements={predictive_model.model_input: transformed_data,\n",
    "                                               #predictive_model.jb_qty_node: np.array([[1], [5]])\n",
    "                                              }).eval()\n",
    "print(jb_qty_preds.shape)\n",
    "print(jb_qty_preds.mean())\n",
    "help(predictive_model.approx.sample_node)\n",
    "\n",
    "#print('r-squared values for predictive model:')\n",
    "#r_squared(predictive_model, val_data.iloc[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Set Up Model-Based Market Simulator\n",
    "\n",
    "I create a market based not on the true data generating processes (which the Jetblue doesn't know), but instead based on the predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_market_conditions = CompetitiveConditions(predictive_model=predictive_model)\n",
    "sim_market = Market(sim_market_conditions, MAX_DEMAND_LEVEL, DEMAND_SIGNAL_NOISINESS, SEATS_PER_FLIGHT, SALES_WINDOW_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As a diagnostic, I compare predicted profits from using Jetblue's current pricing function in the training, validation and simulator data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_price_sim_profits, simple_price_sim_data = run_env(sim_market, simple_price_fn, n_times=20)\n",
    "\n",
    "print(\"Mean profits in training data: ${:,.0f} \\n\"\n",
    "      \"Mean profits in val data: ${:,.0f} \\n\"\n",
    "      \"Mean profits in sim data: ${:,.0f} \\n\".format(train_profits.mean(), val_profits.mean(), simple_price_sim_profits.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.sample_posterior_predictive?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1 Model Diagnostics\n",
    "This modeling set-up allows a wide range of diagnostics counterfactual tests. I don't explore those here, though we would do this to improve the model in a real application. As a first example, I plot a demand curve and cross-price demand curve showing how predicted ticket sales vary with respect to Jetblue's prices (holding other factors constant.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_before_flight = jb_demand_signal = 150\n",
    "pred_outcomes_diff_jb_prices = []\n",
    "for jb_price in np.linspace(0, MAX_DEMAND_LEVEL, 6):\n",
    "    # Some extra munging here do to messiness associated with multi-input / multi-output model.\n",
    "    # each input fed in as separate array to facilitate hiding jetblue_price from prediction of delta_price\n",
    "prediction_data = prep_for_keras_model([days_before_flight, jb_demand_signal, jb_price], skip_y=True)\n",
    "    prediction = predictive_model.predict(prediction_data)\n",
    "    delta_price, jb_seats_sold, delta_seats_sold = [round(i[0][0]) for i in prediction]\n",
    "    pred_outcomes_diff_jb_prices.append({'jb_price': jb_price,\n",
    "                                         'delta_price': delta_price,\n",
    "                                         'jetblue_seats_sold': jb_seats_sold,\n",
    "                                         'delta_seats_sold': delta_seats_sold})\n",
    "pd.DataFrame(pred_outcomes_diff_jb_prices).set_index(['jb_price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It isn't surprising that delta price is independent of **jb_price**. The structural model asserts that neither airline sees the other price on any given day before they choose their own.  However, any non-monotonicities in the `seats_sold` predictions are limitations of the predictive model.\n",
    "\n",
    "Even with an imperfect model, pricing policy optimization can work well, with optimized policies yielding far greater profits in the real environment than the baseline pricing function did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Optimize Policy Function\n",
    "We could use an arbitrary optimization procedure to optimize our policy. The appendix contains a Soft Actor Critic optimizer, and I may experiment with other optimizers in the future. For now, I use a simple grid search. Pricing policies are created as linear functions of the state variables\n",
    "- Daily demand signal\n",
    "- Days remaining before flight\n",
    "- Seats available\n",
    "- Whether the competitor's flight is full\n",
    "\n",
    "I try various multipliers of these state variables. The pricing equation is specified more precisely [here](https://github.com/dansbecker/sem_policy_opt/blob/master/sem_policy_opt/diagnostics.py#L9).\n",
    "\n",
    "The optimization code is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from itertools import product\n",
    "from time import time\n",
    "from sem_policy_opt.diagnostics import pricing_fn_creator, get_real_and_sim_rewards\n",
    "\n",
    "optim_start_time = time()\n",
    "\n",
    "# Create points in grid of pricing policies to be considered during optimization\n",
    "intercepts = np.linspace(0, 200, 4)\n",
    "demand_signal_mults = np.linspace(0, 1, 4)\n",
    "days_before_flight_mults = np.linspace(0, 1, 4)\n",
    "seats_avail_mults = np.linspace(-1, 0, 3)\n",
    "competitor_full_mults = np.linspace(0, 100, 3)\n",
    "price_floors = np.linspace(0, 100, 3)\n",
    "\n",
    "pricing_combinations = product(intercepts, demand_signal_mults, days_before_flight_mults, \n",
    "                               seats_avail_mults, competitor_full_mults, price_floors)\n",
    "\n",
    "pricing_fns = [pricing_fn_creator(*params) for params in pricing_combinations]\n",
    "real_and_sim_rewards = get_real_and_sim_rewards(real_market, sim_market, pricing_fns)\n",
    "\n",
    "print(\"Optimation time: {}\".format(int(time()-optim_start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A firm would select the policy that returns the highest predicted profit in simulation (since simulation is all they can see before implementing a new policy). This process is effective to the extent the policy generates higher profits in the true market environment. Predicted and real profits from various policies are shown in the following graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "from sem_policy_opt.diagnostics import plot_optim_results\n",
    "\n",
    "plot_optim_results(real_and_sim_rewards, \n",
    "                   baseline_real_profits=val_profits.mean(), \n",
    "                   baseline_sim_profits=simple_price_sim_profits.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis\n",
    "\n",
    "The optimization process appears effective. Did this hinge critically on the quality of the predictive model?\n",
    "\n",
    "The firm predicts demand each day from a \"demand signal\", and we have a variable that specifies how noisy these signals are.\n",
    "\n",
    "The following test varies the amount of noise in the demand signal. This in turn varies the quality of the predictive model (i.e. as measured with r-squared). The result shows the relationship between quality of the predictive model and effectiveness of policy optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sem_policy_opt.diagnostics import sensitivity_analysis\n",
    "\n",
    "noisy_real_market_maker = lambda demand_noisiness: Market(real_market_conditions, MAX_DEMAND_LEVEL, demand_noisiness, SEATS_PER_FLIGHT, SALES_WINDOW_LENGTH)\n",
    "noisy_sim_market_maker = lambda demand_noisiness, sim_conditions: Market(sim_conditions, MAX_DEMAND_LEVEL, demand_noisiness, SEATS_PER_FLIGHT, SALES_WINDOW_LENGTH)\n",
    "\n",
    "sensitivity_results = sensitivity_analysis(noisy_real_market_maker, \n",
    "                                           noisy_sim_market_maker, \n",
    "                                           noise_levels = [20, 50, 100, 250],\n",
    "                                           pricing_fns=pricing_fns,\n",
    "                                           flights_in_training_data = FLIGHTS_IN_TRAINING_DATA,\n",
    "                                           baseline_price_fn=simple_price_fn)\n",
    "sensitivity_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real profits from policy optimization decrease as the environment gets noisier (and the model gets worse). This is due to worsening optimization (and not a change in the best possible policy), as the real profits from a perfectly chosen policy remain high.\n",
    "\n",
    "Optimization beats the baseline in all circumstances, though this may be an unfair comparison as the baseline policy was chosen from ad-hoc experimentation when the baseline noise level was 20.\n",
    "\n",
    "Fortunately, simulated profits are close to real profits in all cases. So a firm would have a reasonable estimate of real profits before deploying any policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concerns\n",
    "Price optimization nearly doubled real profits in the main example, and it consistently improved them. But I see three primary objections to this example:\n",
    "\n",
    "1) This improvement is over a baseline I created through trial and error, not a policy used in the real world (I certainly don't mean to suggest that a Fortune 500 company could double revenue this easily).\n",
    "\n",
    "2) This example is a somewhat simple problem: there are only two airlines and we didn't account for factors like seasonality. It would be straightforward to include these factors in the model, though I've yet to show how well the process works in a more complex environment.\n",
    "\n",
    "3) Most concerning, it's unclear how to show that a policy created through optimization will work well without applying it (there's nothing like a test set from supervised ML).\n",
    "\n",
    "Nevertheless, I believe this approach optimizing decision logic has amazing potential, possibly of the same order of magnitude as what we are seeing from supervised ML.\n",
    "\n",
    "I appreciate any suggestions and criticisms so I can improve the argument I've started in this notebook.\n",
    "\n",
    "# Potential Next Steps\n",
    "\n",
    "I'm currently considering the following next steps:\n",
    "\n",
    "1. Use PyMC3 for predictive model, and do optimization averaging over multiple simulation environments sampled from the predictive model posterior (to address Jensen's inequality)\n",
    "2. Abstract out the logic that's universal vs use-case specific\n",
    "3. Run on real (static) dataset rather than synthetic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "### How The Market In This Example Works\n",
    "Some number of customers (`POTENTIAL_CUSTOMERS_PER_DAY`) come to a website each day.  The customers' average willingness to pay for a flight on that day `demand_level`. The `demand level` on any given day is chosen from a distribution `uniform(0, MAX_DEMAND_LEVEL)`.  Each airline receives a signal about `demand_level` on that day, and the signal is the `demand_level` plus some noise that is distributed `N(0, DEMAND_SIGNAL_NOISINESS)`. This demand signal might represent a prediction of demand from a model considering seasonality, macroeconomics, etc. Additionally, each customer has idiosyncratic preferences, so their willingness to pay for a ticket on any given airline is `demand_level + customer_preference` where `customer_preference` is distributed `N(0, CUSTOMER_LEVEL_RANDOMNESS)`.  The customer considers the price for each of the two airlines and purchases a ticket from the airline that gives them the highest consumer surplus (their personal willingness to pay minus for a ticket on that airline minus the cost of a ticket on that airline).  If the customer's consumer surplus for both airlines is negative, they do not buy a ticket.\n",
    "\n",
    "### Optimization Through Modern Reinforcement Learning\n",
    "\n",
    "The cell below optimizes the pricing policy with Soft Actor Critic (SAC), an RL algorithm that is sample efficient and which is reported to require little hyperparameter tuning.\n",
    "\n",
    "NOTE: I am sharing this notebook output in Kaggle Kernels. I've not yet been able to install `stable_baselines` in kernels, so I've commented this part out for now. The value of my underlying approach doesn't hinge on whether I do optimization through SAC, grid search (used above) or something else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:    # disabled until I install stable_baselines in Kernels\n",
    "    from stable_baselines.common.vec_env import DummyVecEnv\n",
    "    from stable_baselines.sac.policies import MlpPolicy\n",
    "    from stable_baselines.sac import SAC\n",
    "    from time import time\n",
    "    import os\n",
    "\n",
    "    sim_market_maker = lambda: market_maker(sim_market_conditions)\n",
    "    \n",
    "    parallelism_level = 1         # use os.cpu_count() if not using SAC. SAC doesn't allow parallelism\n",
    "    env = DummyVecEnv([sim_market_maker for _ in range(parallelism_level)]) # Env is vectorized market for parallelism\n",
    "    total_learning_steps = 750000\n",
    "    steps_per_update = 10000\n",
    "    optim_results = []\n",
    "\n",
    "    model = SAC(MlpPolicy, env)\n",
    "\n",
    "    start_time = time()\n",
    "    for step in range(0, total_learning_steps+1, steps_per_update):\n",
    "        model.learn(total_timesteps=steps_per_update)\n",
    "    \n",
    "        mean_sim_reward = run_env(sim_market_maker, model, n_times=5)[0].mean()\n",
    "        mean_real_reward = run_env(real_market_maker, model, n_times=5)[0].mean()\n",
    "        optim_results.append(dict(step=step, \n",
    "                                  time=time()-start_time,\n",
    "                                  sim_profit=mean_sim_reward,\n",
    "                                  real_profit=mean_real_reward))\n",
    "    \n",
    "        print(\"\"\"{} timesteps used for learning in {:.0f} seconds. \n",
    "                 Current score in sim: {:.0f}. Current score in real market: {:.0f}.\"\"\".format(\n",
    "                                                                                step,\n",
    "                                                                                time()-start_time, \n",
    "                                                                                mean_sim_reward, \n",
    "                                                                                mean_real_reward))\n",
    "    optim_results_df = pd.DataFrame(optim_results)\n",
    "    optim_results_df.plot.line(x='step', y=['sim_profit', 'real_profit'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
